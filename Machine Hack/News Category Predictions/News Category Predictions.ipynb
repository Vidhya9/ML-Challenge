{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  \n",
    "import nltk\n",
    "import string\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\",200)\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORY</th>\n",
       "      <th>SECTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But the most painful was the huge reversal in fee income, unheard of among private sector lenders. Essentially, it means that Yes Bank took it for granted that fees on structured loan deals will b...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How formidable is the opposition alliance among Congress, Jharkhand Mukti Morcha (JMM) and Jharkhand Vikas Morcha (Prajatantrik)?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most Asian currencies were trading lower today. South Korean won was down 0.4%, China renminbi 0.23%, China Offshore 0.15%, Malaysian ringgit 0.12%, Indonesian rupiah 0.11%, Taiwan dollar 0.06%. H...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you want to answer any question, click on ‘Answer’. After clicking on Answer you can also check out replies of other users. Proceed to Answer either through writing or voice command.\\n\\n\\nIf yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In global markets, gold prices edged up today as disappointing Chinese factory activity data brought back concerns about the health of the global economy, denting risk appetite. Spot gold rose 0.4...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                     STORY  \\\n",
       "0  But the most painful was the huge reversal in fee income, unheard of among private sector lenders. Essentially, it means that Yes Bank took it for granted that fees on structured loan deals will b...   \n",
       "1                                                                        How formidable is the opposition alliance among Congress, Jharkhand Mukti Morcha (JMM) and Jharkhand Vikas Morcha (Prajatantrik)?   \n",
       "2  Most Asian currencies were trading lower today. South Korean won was down 0.4%, China renminbi 0.23%, China Offshore 0.15%, Malaysian ringgit 0.12%, Indonesian rupiah 0.11%, Taiwan dollar 0.06%. H...   \n",
       "3  If you want to answer any question, click on ‘Answer’. After clicking on Answer you can also check out replies of other users. Proceed to Answer either through writing or voice command.\\n\\n\\nIf yo...   \n",
       "4  In global markets, gold prices edged up today as disappointing Chinese factory activity data brought back concerns about the health of the global economy, denting risk appetite. Spot gold rose 0.4...   \n",
       "\n",
       "   SECTION  \n",
       "0        3  \n",
       "1        0  \n",
       "2        3  \n",
       "3        1  \n",
       "4        3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train =pd.read_excel('Data_train.xlsx')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019 will see gadgets like gaming smartphones and wearable medical devices lifting the user experience to a whole new level\\n\\n\\nmint-india-wire consumer technologyconsumer technology trends in Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It has also unleashed a wave of changes in the MCU that will make sure its future is a lot different than its past\\n\\n\\nKevin Feige had signalled diversity and more representation in the post-phas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It can be confusing to pick the right smartphone for yourself, so we have segregated the top smartphones under Rs 20,000 according to their strengths.\\n\\n\\nThe best smartphones under ₹20,000 categ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The mobile application is integrated with a dashboard to confirm and register the pre-registered cases, to enable online interface between the beneficiary and the panel lawyer through video confer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have rounded up some of the gadgets that showed up in 2018 and left an indelible mark on, consumers, experts and the tech industry\\n\\n\\nYoungsters playing PUBG Mobile on their smartphone for ho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                     STORY\n",
       "0  2019 will see gadgets like gaming smartphones and wearable medical devices lifting the user experience to a whole new level\\n\\n\\nmint-india-wire consumer technologyconsumer technology trends in Ne...\n",
       "1  It has also unleashed a wave of changes in the MCU that will make sure its future is a lot different than its past\\n\\n\\nKevin Feige had signalled diversity and more representation in the post-phas...\n",
       "2  It can be confusing to pick the right smartphone for yourself, so we have segregated the top smartphones under Rs 20,000 according to their strengths.\\n\\n\\nThe best smartphones under ₹20,000 categ...\n",
       "3  The mobile application is integrated with a dashboard to confirm and register the pre-registered cases, to enable online interface between the beneficiary and the panel lawyer through video confer...\n",
       "4  We have rounded up some of the gadgets that showed up in 2018 and left an indelible mark on, consumers, experts and the tech industry\\n\\n\\nYoungsters playing PUBG Mobile on their smartphone for ho..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test =pd.read_excel('Data_test.xlsx')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7628, 2), (2748, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape , test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.duplicated().sum(), test.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7551, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=train[train.duplicated()==False].reset_index()\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2731\n",
       "2    1914\n",
       "0    1673\n",
       "3    1233\n",
       "Name: SECTION, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SECTION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(index      0\n",
       " STORY      0\n",
       " SECTION    0\n",
       " dtype: int64, STORY    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum(),test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "combi = train.append(test , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi.STORY = combi.STORY.str.replace(r\"\\n+\", \" \")\n",
    "combi.STORY = combi.STORY.str.replace(r\"(\\d)\", \"\")\n",
    "#combi.STORY = combi.STORY.str.replace(r\".%\", \"\")\n",
    "combi.STORY = combi.STORY.str.replace(r\"[^A-Za-z]\", \" \")\n",
    "combi.STORY = combi.STORY.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SECTION</th>\n",
       "      <th>STORY</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>painful huge reversal fee income unheard among private sector lenders essentially means yes bank took granted fees structured loan deals paid accounted upfront books borrowers turned defaulters fe...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>formidable opposition alliance among congress jharkhand mukti morcha jmm jharkhand vikas morcha prajatantrik</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>asian currencies trading lower today south korean china renminbi china offshore malaysian ringgit indonesian rupiah taiwan dollar however japanese yen dollar index measures us currency strength ma...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>want answer question click answer clicking answer also check replies users proceed answer either writing voice command want ask question click ask question question prefixes already inserted help ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>global markets gold prices edged today disappointing chinese factory activity data brought back concerns health global economy denting risk appetite spot gold rose per ounce european equity market...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SECTION  \\\n",
       "0      3.0   \n",
       "1      0.0   \n",
       "2      3.0   \n",
       "3      1.0   \n",
       "4      3.0   \n",
       "\n",
       "                                                                                                                                                                                                     STORY  \\\n",
       "0  painful huge reversal fee income unheard among private sector lenders essentially means yes bank took granted fees structured loan deals paid accounted upfront books borrowers turned defaulters fe...   \n",
       "1                                                                                             formidable opposition alliance among congress jharkhand mukti morcha jmm jharkhand vikas morcha prajatantrik   \n",
       "2  asian currencies trading lower today south korean china renminbi china offshore malaysian ringgit indonesian rupiah taiwan dollar however japanese yen dollar index measures us currency strength ma...   \n",
       "3  want answer question click answer clicking answer also check replies users proceed answer either writing voice command want ask question click ask question question prefixes already inserted help ...   \n",
       "4  global markets gold prices edged today disappointing chinese factory activity data brought back concerns health global economy denting risk appetite spot gold rose per ounce european equity market...   \n",
       "\n",
       "   index  \n",
       "0    0.0  \n",
       "1    1.0  \n",
       "2    2.0  \n",
       "3    3.0  \n",
       "4    4.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "combi.STORY= combi.STORY.apply(lambda x : \" \".join([w for w in x.split() if w not in stop]))\n",
    "combi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [painful, huge, reversal, fee, income, unheard, among, private, sector, lenders, essentially, means, yes, bank, took, granted, fees, structured, loan, deals, paid, accounted, upfront, books, borro...\n",
       "1                                                                                 [formidable, opposition, alliance, among, congress, jharkhand, mukti, morcha, jmm, jharkhand, vikas, morcha, prajatantrik]\n",
       "2    [asian, currencies, trading, lower, today, south, korean, china, renminbi, china, offshore, malaysian, ringgit, indonesian, rupiah, taiwan, dollar, however, japanese, yen, dollar, index, measures,...\n",
       "3    [want, answer, question, click, answer, clicking, answer, also, check, replies, users, proceed, answer, either, writing, voice, command, want, ask, question, click, ask, question, question, prefix...\n",
       "4    [global, markets, gold, prices, edged, today, disappointing, chinese, factory, activity, data, brought, back, concerns, health, global, economy, denting, risk, appetite, spot, gold, rose, per, oun...\n",
       "Name: STORY, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = combi['STORY'].apply(lambda x: x.split())\n",
    "tokenized_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "from nltk.stem.porter import *\n",
    "stemmer=PorterStemmer()\n",
    "tokenized_text = tokenized_text.apply(lambda x: [stemmer.stem(i) for i in x])   #stemming\n",
    "#Lemmatizing - is giving less accurate so used\n",
    "#from nltk.stem import WordNetLemmatizer \n",
    "#lemmatizer = WordNetLemmatizer() \n",
    "#tokenized_text1 = tokenized_text.apply(lambda x: [lemmatizer.lemmatize(i) for i in x])   #lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stitch these tokens back together\n",
    "for i in range(len(tokenized_text)):\n",
    "    tokenized_text[i] = ' '.join(tokenized_text[i])\n",
    "combi['TIDY_STORY'] = tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10299, 1000)\n"
     ]
    }
   ],
   "source": [
    "#Count Vectoriser\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_vectorizer=CountVectorizer(max_df=0.90,min_df=2,max_features=1000,stop_words='english')\n",
    "bow = bow_vectorizer.fit_transform(combi['TIDY_STORY'])\n",
    "print(bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10299, 1000)\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer=TfidfVectorizer(max_df=0.90,min_df=2,max_features=1000,stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(combi['TIDY_STORY'])\n",
    "print(tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12481057, 12900340)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "tokenized_text = combi['TIDY_STORY'].apply(lambda x: x.split()) # tokenizing \n",
    "\n",
    "model_w2v = gensim.models.Word2Vec(\n",
    "            tokenized_text,\n",
    "            size=200, # desired no. of features/independent variables-300\n",
    "            window=5, # context window size -7\n",
    "            min_count=2,  # Minimum word count threshold\n",
    "            sg = 1, # 1 for skip-gram model\n",
    "            hs = 0,\n",
    "            negative = 10, # for negative sampling\n",
    "            workers= 4, # no.of cores\n",
    "            #sampling=#0=1e-3      #Downsample setting for frequent words-  1e-5  \n",
    "            seed = 34) \n",
    "model_w2v.train(tokenized_text, total_examples= len(combi['TIDY_STORY']), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_w2v[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError: # handling the case where the token is not in vocabulary                                     \n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10299, 200)\n"
     ]
    }
   ],
   "source": [
    "wordvec_arrays = np.zeros((len(tokenized_text), 200)) \n",
    "for i in range(len(tokenized_text)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_text[i], 200)\n",
    "wordvec_df = pd.DataFrame(wordvec_arrays) \n",
    "print(wordvec_df.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "tqdm.pandas(desc=\"progress-bar\") \n",
    "from gensim.models.doc2vec import LabeledSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label(twt):\n",
    "    output = []\n",
    "    for i, s in zip(twt.index, twt):\n",
    "        output.append(LabeledSentence(s, [\"text_\" + str(i)]))\n",
    "    return output\n",
    "labeled_texts = add_label(tokenized_text) # label all the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 10299/10299 [00:00<00:00, 936401.48it/s]\n"
     ]
    }
   ],
   "source": [
    "#Now let’s train a doc2vec model.\n",
    "model_d2v = gensim.models.Doc2Vec(\n",
    "    dm=1, # dm = 1 for ‘distributed memory’ model                                  \n",
    "    dm_mean=1, # dm = 1 for using mean of the context word vectors                                 \n",
    "    vector_size=200, # no. of desired features                                  \n",
    "    window=5, # width of the context window                                  \n",
    "    negative=7, # if > 0 then negative sampling will be used                                 \n",
    "    min_count=5, # Ignores all words with total frequency lower than 2.                                  \n",
    "    workers=3, # no. of cores                                  \n",
    "    alpha=0.1, # learning rate                                  \n",
    "    seed = 23) \n",
    "model_d2v.build_vocab([i for i in tqdm(labeled_texts)])\n",
    "model_d2v.train(labeled_texts, total_examples= len(combi['TIDY_STORY']), epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10299, 200)\n"
     ]
    }
   ],
   "source": [
    "#Preparing doc2vec Feature Set\n",
    "docvec_arrays = np.zeros((len(tokenized_text), 200)) \n",
    "for i in range(len(combi)):\n",
    "    docvec_arrays[i,:] = model_d2v.docvecs[i].reshape((1,200))    \n",
    "\n",
    "docvec_df = pd.DataFrame(docvec_arrays) \n",
    "print(docvec_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docvec_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-8b630fcb1c77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m#Doc2Vec Features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mtrain_d2v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdocvec_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m7551\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mtest_d2v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdocvec_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7551\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mxtrain_d2v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_d2v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'docvec_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Splitting into  train and test features \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import f1_score , accuracy_score,confusion_matrix , classification_report\n",
    "\n",
    "# Bag-of-Words Features\n",
    "train_bow = bow[:7551,:]\n",
    "test_bow = bow[7551:,:]\n",
    "xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(train_bow, train['SECTION'], random_state=1,test_size=0.2) #2\n",
    "\n",
    "#TF_IDF Bag-of-Words Features\n",
    "train_tfidf = tfidf[:7551,:]\n",
    "test_tfidf = tfidf[7551:,:]\n",
    "xtrain_tfidf = train_tfidf[ytrain.index] \n",
    "xvalid_tfidf = train_tfidf[yvalid.index]\n",
    "\n",
    "#Word2Vec Features\n",
    "train_w2v = wordvec_df.iloc[:7551,:]\n",
    "test_w2v = wordvec_df.iloc[7551:,:] \n",
    "xtrain_w2v = train_w2v.iloc[ytrain.index,:] \n",
    "xvalid_w2v = train_w2v.iloc[yvalid.index,:]\n",
    "\n",
    "#Doc2Vec Features\n",
    "train_d2v = docvec_df.iloc[:7551,:] \n",
    "test_d2v = docvec_df.iloc[7551:,:] \n",
    "xtrain_d2v = train_d2v.iloc[ytrain.index,:] \n",
    "xvalid_d2v = train_d2v.iloc[yvalid.index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9510258107213766\n",
      "f1score 0.9510284519624431\n",
      "[[326   7  10   1]\n",
      " [  7 518  14  10]\n",
      " [  3   5 368   1]\n",
      " [  4   7   5 225]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       344\n",
      "           1       0.96      0.94      0.95       549\n",
      "           2       0.93      0.98      0.95       377\n",
      "           3       0.95      0.93      0.94       241\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      1511\n",
      "   macro avg       0.95      0.95      0.95      1511\n",
      "weighted avg       0.95      0.95      0.95      1511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bag-of-Words Features\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(max_depth=6, n_estimators=1000).fit(xtrain_bow, ytrain) \n",
    "prediction = xgb_model.predict(xvalid_bow) \n",
    "print('accuracy',accuracy_score(yvalid, prediction))  \n",
    "print('f1score',f1_score(y_true=yvalid, y_pred=prediction, average='weighted'))\n",
    "print(confusion_matrix(yvalid, prediction))  \n",
    "print(classification_report(y_true=yvalid, y_pred=prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(max_depth=6, n_estimators=1000).fit(train_bow, train['SECTION']) \n",
    "test_pred = xgb_model.predict(test_bow) \n",
    "test['SECTION'] = test_pred \n",
    "submission = test['SECTION'] \n",
    "submission.to_excel('xgb_bow.xlsx', index=False)   #96.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9523494374586366\n",
      "f1score 0.9524388622657395\n",
      "[[326   5  12   1]\n",
      " [  4 520  16   9]\n",
      " [  2   6 367   2]\n",
      " [  3   7   5 226]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       344\n",
      "           1       0.97      0.95      0.96       549\n",
      "           2       0.92      0.97      0.94       377\n",
      "           3       0.95      0.94      0.94       241\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      1511\n",
      "   macro avg       0.95      0.95      0.95      1511\n",
      "weighted avg       0.95      0.95      0.95      1511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF Features\n",
    "xgb = XGBClassifier(max_depth=6, n_estimators=1000).fit(xtrain_tfidf, ytrain) \n",
    "prediction = xgb.predict(xvalid_tfidf) \n",
    "print('accuracy',accuracy_score(yvalid, prediction))  \n",
    "print('f1score',f1_score(y_true=yvalid, y_pred=prediction, average='weighted'))\n",
    "print(confusion_matrix(yvalid, prediction))  \n",
    "print(classification_report(y_true=yvalid, y_pred=prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=6, n_estimators=1000).fit(train_tfidf, train['SECTION']) \n",
    "test_pred = xgb.predict(test_bow) \n",
    "test['SECTION'] = test_pred \n",
    "submission = test['SECTION'] \n",
    "submission.to_excel('xgb_tfidf.xlsx', index=False)  #87.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.970880211780278\n",
      "f1score 0.9708629935924304\n",
      "[[328   8   6   2]\n",
      " [  2 534   6   7]\n",
      " [  5   2 370   0]\n",
      " [  3   2   1 235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       344\n",
      "           1       0.98      0.97      0.98       549\n",
      "           2       0.97      0.98      0.97       377\n",
      "           3       0.96      0.98      0.97       241\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1511\n",
      "   macro avg       0.97      0.97      0.97      1511\n",
      "weighted avg       0.97      0.97      0.97      1511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=6, n_estimators=1000, nthread= 3).fit(xtrain_w2v, ytrain) \n",
    "prediction = xgb.predict(xvalid_w2v) \n",
    "print('accuracy',accuracy_score(yvalid, prediction))  \n",
    "print('f1score',f1_score(y_true=yvalid, y_pred=prediction, average='weighted'))\n",
    "print(confusion_matrix(yvalid, prediction))  \n",
    "print(classification_report(y_true=yvalid, y_pred=prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=6, n_estimators=1000).fit(train_w2v, train['SECTION']) \n",
    "test_pred = xgb.predict(test_w2v) \n",
    "test['SECTION'] = test_pred \n",
    "submission = test['SECTION']   \n",
    "submission.to_excel('xgb_w2v.xlsx', index=False)  #97.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9126406353408338\n",
      "f1score 0.9125662466644285\n",
      "[[302  21  17   4]\n",
      " [ 11 506  19  13]\n",
      " [  7  16 351   3]\n",
      " [  6  10   5 220]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       344\n",
      "           1       0.92      0.92      0.92       549\n",
      "           2       0.90      0.93      0.91       377\n",
      "           3       0.92      0.91      0.91       241\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      1511\n",
      "   macro avg       0.91      0.91      0.91      1511\n",
      "weighted avg       0.91      0.91      0.91      1511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Doc2Vec Features\n",
    "xgb = XGBClassifier(max_depth=6, n_estimators=1000, nthread= 3).fit(xtrain_d2v, ytrain) \n",
    "prediction = xgb.predict(xvalid_d2v) \n",
    "print('accuracy',accuracy_score(yvalid, prediction))  \n",
    "print('f1score',f1_score(y_true=yvalid, y_pred=prediction, average='weighted')) \n",
    "print(confusion_matrix(yvalid, prediction))  \n",
    "print(classification_report(y_true=yvalid, y_pred=prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=6, n_estimators=1000).fit(train_d2v, train['SECTION']) \n",
    "test_pred = xgb.predict(test_d2v) \n",
    "test['SECTION'] = test_pred \n",
    "submission = test['SECTION'] \n",
    "submission.to_excel('xgb_d2v.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 22 seconds\n",
      "accuracy 0.9470549305095963\n",
      "f1score 0.9471211715881157\n",
      "[[326   6  10   2]\n",
      " [  6 518  14  11]\n",
      " [  7   7 358   5]\n",
      " [  3   6   3 229]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       344\n",
      "           1       0.96      0.94      0.95       549\n",
      "           2       0.93      0.95      0.94       377\n",
      "           3       0.93      0.95      0.94       241\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      1511\n",
      "   macro avg       0.94      0.95      0.95      1511\n",
      "weighted avg       0.95      0.95      0.95      1511\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   21.8s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C=30, class_weight='balanced', solver='sag', \n",
    "                         multi_class='multinomial', n_jobs=-1, random_state=40, \n",
    "                         verbose=1, max_iter = 1000)\n",
    "clf.fit(xtrain_bow, ytrain)\n",
    "prediction = clf.predict(xvalid_bow) \n",
    "print('accuracy',accuracy_score(yvalid, prediction))  \n",
    "print('f1score',f1_score(y_true=yvalid, y_pred=prediction, average='weighted'))\n",
    "print(confusion_matrix(yvalid, prediction))  \n",
    "print(classification_report(y_true=yvalid, y_pred=prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9622766379880874\n",
      "f1score 0.9622771722715061\n",
      "[[328   5   9   2]\n",
      " [  7 524   9   9]\n",
      " [  5   4 368   0]\n",
      " [  3   4   0 234]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       344\n",
      "           1       0.98      0.95      0.97       549\n",
      "           2       0.95      0.98      0.96       377\n",
      "           3       0.96      0.97      0.96       241\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1511\n",
      "   macro avg       0.96      0.96      0.96      1511\n",
      "weighted avg       0.96      0.96      0.96      1511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=30, class_weight='balanced', solver='sag', \n",
    "                         multi_class='multinomial', n_jobs=-1, random_state=40, \n",
    "                         verbose=1, max_iter = 1000)\n",
    "clf.fit(xtrain_w2v, ytrain)\n",
    "prediction = clf.predict(xvalid_w2v) \n",
    "print('accuracy',accuracy_score(yvalid, prediction))  #0.7380050505050505\n",
    "print('f1score',f1_score(y_true=yvalid, y_pred=prediction, average='weighted'))\n",
    "print(confusion_matrix(yvalid, prediction))  \n",
    "print(classification_report(y_true=yvalid, y_pred=prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9470549305095963\n",
      "f1score 0.9471211715881157\n",
      "accuracy [[326   6  10   2]\n",
      " [  6 518  14  11]\n",
      " [  7   7 358   5]\n",
      " [  3   6   3 229]]\n",
      "f1score               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       344\n",
      "           1       0.96      0.94      0.95       549\n",
      "           2       0.93      0.95      0.94       377\n",
      "           3       0.93      0.95      0.94       241\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      1511\n",
      "   macro avg       0.94      0.95      0.95      1511\n",
      "weighted avg       0.95      0.95      0.95      1511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(xtrain_bow.toarray(), ytrain)\n",
    "prediction = clf.predict(xvalid_bow) \n",
    "print('accuracy',accuracy_score(yvalid, prediction))  #0.7380050505050505\n",
    "print('f1score',f1_score(y_true=yvalid, y_pred=prediction, average='weighted'))\n",
    "print('accuracy',confusion_matrix(yvalid, prediction))  #0.7380050505050505\n",
    "print('f1score',classification_report(y_true=yvalid, y_pred=prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9622766379880874\n",
      "f1score 0.9622771722715061\n",
      "accuracy [[328   5   9   2]\n",
      " [  7 524   9   9]\n",
      " [  5   4 368   0]\n",
      " [  3   4   0 234]]\n",
      "f1score               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       344\n",
      "           1       0.98      0.95      0.97       549\n",
      "           2       0.95      0.98      0.96       377\n",
      "           3       0.96      0.97      0.96       241\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1511\n",
      "   macro avg       0.96      0.96      0.96      1511\n",
      "weighted avg       0.96      0.96      0.96      1511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb=GaussianNB()\n",
    "nb.fit(xtrain_w2v, ytrain)\n",
    "prediction = clf.predict(xvalid_w2v) \n",
    "print('accuracy',accuracy_score(yvalid, prediction))  #0.7380050505050505\n",
    "print('f1score',f1_score(y_true=yvalid, y_pred=prediction, average='weighted'))\n",
    "print('accuracy',confusion_matrix(yvalid, prediction))  #0.7380050505050505\n",
    "print('f1score',classification_report(y_true=yvalid, y_pred=prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9470549305095963\n",
      "f1score 0.9471211715881157\n",
      "accuracy [[326   6  10   2]\n",
      " [  6 518  14  11]\n",
      " [  7   7 358   5]\n",
      " [  3   6   3 229]]\n",
      "f1score               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       344\n",
      "           1       0.96      0.94      0.95       549\n",
      "           2       0.93      0.95      0.94       377\n",
      "           3       0.93      0.95      0.94       241\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      1511\n",
      "   macro avg       0.94      0.95      0.95      1511\n",
      "weighted avg       0.95      0.95      0.95      1511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sbg=SGDClassifier(loss='modified_huber',shuffle=True,random_state=101).fit(xtrain_bow, ytrain)\n",
    "prediction = clf.predict(xvalid_bow) \n",
    "print('accuracy',accuracy_score(yvalid, prediction))  #0.7380050505050505\n",
    "print('f1score',f1_score(y_true=yvalid, y_pred=prediction, average='weighted'))\n",
    "print('accuracy',confusion_matrix(yvalid, prediction))  #0.7380050505050505\n",
    "print('f1score',classification_report(y_true=yvalid, y_pred=prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9622766379880874\n",
      "f1score 0.9622771722715061\n",
      "accuracy [[328   5   9   2]\n",
      " [  7 524   9   9]\n",
      " [  5   4 368   0]\n",
      " [  3   4   0 234]]\n",
      "f1score               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       344\n",
      "           1       0.98      0.95      0.97       549\n",
      "           2       0.95      0.98      0.96       377\n",
      "           3       0.96      0.97      0.96       241\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1511\n",
      "   macro avg       0.96      0.96      0.96      1511\n",
      "weighted avg       0.96      0.96      0.96      1511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sbg=SGDClassifier(loss='modified_huber',shuffle=True,random_state=101).fit(xtrain_w2v, ytrain)\n",
    "prediction = clf.predict(xvalid_w2v) \n",
    "print('accuracy',accuracy_score(yvalid, prediction))  #0.7380050505050505\n",
    "print('f1score',f1_score(y_true=yvalid, y_pred=prediction, average='weighted'))\n",
    "print('accuracy',confusion_matrix(yvalid, prediction))  #0.7380050505050505\n",
    "print('f1score',classification_report(y_true=yvalid, y_pred=prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.972203838517538\n",
      "f1score 0.9722131394505193\n",
      "accuracy [[330   5   6   3]\n",
      " [  4 535   5   5]\n",
      " [  8   1 368   0]\n",
      " [  2   3   0 236]]\n",
      "f1score               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       344\n",
      "           1       0.98      0.97      0.98       549\n",
      "           2       0.97      0.98      0.97       377\n",
      "           3       0.97      0.98      0.97       241\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1511\n",
      "   macro avg       0.97      0.97      0.97      1511\n",
      "weighted avg       0.97      0.97      0.97      1511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier(learning_rate=0.15, n_estimators=1200,max_depth=9, min_samples_split=1200, min_samples_leaf=60, subsample=0.85, random_state=1, max_features=7,warm_start=True).fit(xtrain_w2v, ytrain)\n",
    "prediction = gb.predict(xvalid_w2v) \n",
    "print('accuracy',accuracy_score(yvalid, prediction))  \n",
    "print('f1score',f1_score(y_true=yvalid, y_pred=prediction, average='weighted'))\n",
    "print('accuracy',confusion_matrix(yvalid, prediction))  \n",
    "print('f1score',classification_report(y_true=yvalid, y_pred=prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate=0.15, n_estimators=1200,max_depth=9, min_samples_split=1200, min_samples_leaf=60, subsample=0.85, random_state=1, max_features=7,warm_start=True)\n",
    "gb.fit(train_w2v, train['SECTION']) \n",
    "test_pred = gb.predict(test_w2v) \n",
    "test['SECTION'] = test_pred \n",
    "submission = test['SECTION']   \n",
    "submission.to_excel('gb_w2v.xlsx', index=False)   #97.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9629384513567174\n",
      "f1score 0.9629301933623033\n",
      "accuracy [[328  10   4   2]\n",
      " [  4 533   8   4]\n",
      " [  8   4 365   0]\n",
      " [  3   9   0 229]]\n",
      "f1score               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       344\n",
      "           1       0.96      0.97      0.96       549\n",
      "           2       0.97      0.97      0.97       377\n",
      "           3       0.97      0.95      0.96       241\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1511\n",
      "   macro avg       0.96      0.96      0.96      1511\n",
      "weighted avg       0.96      0.96      0.96      1511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "ab= AdaBoostClassifier(n_estimators=1200, base_estimator=dt,random_state=1,learning_rate=0.15).fit(xtrain_w2v, ytrain)\n",
    "prediction = ab.predict(xvalid_w2v) \n",
    "print('accuracy',accuracy_score(yvalid, prediction))  \n",
    "print('f1score',f1_score(y_true=yvalid, y_pred=prediction, average='weighted'))\n",
    "print('accuracy',confusion_matrix(yvalid, prediction))  \n",
    "print('f1score',classification_report(y_true=yvalid, y_pred=prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Public Leaderboard Score-0.9752"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
